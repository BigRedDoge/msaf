{
 "metadata": {
  "name": "",
  "signature": "sha256:d5883498257ee12af8f19495191059d70c10110f487fa0f8fde0de8df3e96b89"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import os\n",
      "import sys\n",
      "import jams2\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy.spatial import distance\n",
      "import add_bounds as AB\n",
      "\n",
      "sys.path.append(\"..\")\n",
      "import msaf_io as MSAF\n",
      "import eval2 as EV\n",
      "import mir_eval\n",
      "\n",
      "# Main ds folder\n",
      "ds_path = \"/Users/uri/datasets/Segments\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Obtain all the annotated boundaries\n",
      "\n",
      "# Get all annotations\n",
      "jam_files = glob.glob(os.path.join(ds_path, \"annotations\", \"*.jams\"))\n",
      "\n",
      "# Read all boundaries\n",
      "all_boundaries = []\n",
      "all_files = []\n",
      "for jam_file in jam_files:\n",
      "    ds_prefix = os.path.basename(jam_file).split(\"_\")[0]\n",
      "    try:\n",
      "        ann_inter, ann_labels = jams2.converters.load_jams_range(\n",
      "            jam_file, \"sections\", annotator=0, context=MSAF.prefix_dict[ds_prefix])\n",
      "    except:\n",
      "        print \"Warning: no annotations for file %s\" % jam_file\n",
      "        continue\n",
      "    ann_times = EV.intervals_to_times(ann_inter)\n",
      "    all_boundaries.append(ann_times)\n",
      "    all_files.append(jam_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1030.jams\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1030.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1040.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1040.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1052.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1052.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1126.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1126.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1140.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1140.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1178.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1178.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1320.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1320.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1398.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1398.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1410.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1410.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1426.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1426.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1430.jams\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1430.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1440.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1440.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1466.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1466.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1486.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1486.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_1500.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_1500.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_872.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_872.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_918.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_918.jams\n",
        "Warning: sections empty in file /Users/uri/datasets/Segments/annotations/SALAMI_966.jams"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: no annotations for file /Users/uri/datasets/Segments/annotations/SALAMI_966.jams\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Obtain all the excerpts that contain at least \"nbounds\" annotated boundaries within \"th\" seconds\n",
      "\n",
      "th = 80\n",
      "nbounds = 8\n",
      "\n",
      "B = nbounds - 1\n",
      "b_offset = 2\n",
      "\n",
      "excerpts = []  # List of tuples (audio_file, boundaries, start_bound_idx)\n",
      "for or_bounds, jam_file in zip(all_boundaries, all_files):\n",
      "    bounds = or_bounds[b_offset:-1]  # Remove first offset and last boundary\n",
      "    for i, bound in enumerate(bounds[:-B]):\n",
      "        if th >= bounds[i+B] - bound:\n",
      "            audio_file = jam_file.replace(\"annotations\", \"audio\").replace(\"jams\", \"mp3\")\n",
      "            if not os.path.isfile(audio_file):\n",
      "                audio_file = audio_file.replace(\"mp3\", \"wav\")\n",
      "            excerpts.append((audio_file, or_bounds, i+b_offset))\n",
      "            break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save excertps to disk\n",
      "tmp_file = \"tmpo.wav\"\n",
      "out_folder = \"audio/\"\n",
      "t_offset = 5\n",
      "reload(AB)\n",
      "\n",
      "def get_extra_bounds(bounds, N=1):\n",
      "    \"\"\"Ads an extra boundary to the longest gap between boundaries.\"\"\"\n",
      "    # TODO: Align to downbeat\n",
      "    for n in xrange(N):\n",
      "        idx = np.argmax(np.diff(bounds))\n",
      "        extra_bound = (bounds[idx+1] - bounds[idx]) / 2.0 + bounds[idx]\n",
      "        bounds = list(bounds)\n",
      "        bounds.insert(idx+1, extra_bound)\n",
      "    return bounds\n",
      "\n",
      "def get_less_bounds(bounds, N=1):\n",
      "    \"\"\"Ads an extra boundary to the longest gap between boundaries.\"\"\"\n",
      "    for n in xrange(N):\n",
      "        idx = np.argmin(np.diff(bounds))\n",
      "        bounds = list(bounds)\n",
      "        bounds.pop(idx+1)\n",
      "    return bounds\n",
      "\n",
      "def get_excerpt_bounds(excerpt):\n",
      "    \"\"\"Gets the excerpt boundaries.\"\"\"\n",
      "    bounds = excerpt[1]\n",
      "    start_idx = excerpt[2]\n",
      "    excerpt_bounds = []\n",
      "    start_time = bounds[start_idx]\n",
      "    for b in bounds[start_idx:]:\n",
      "        if b - start_time < th:\n",
      "            excerpt_bounds.append(b)\n",
      "    return excerpt_bounds\n",
      "\n",
      "def eval_bounds(synth_bounds, ann_bounds):\n",
      "    \"\"\"Evaluates the synthesized boundaries agains the annotated ones.\"\"\"\n",
      "    synth_inter = EV.times_to_intervals(synth_bounds)\n",
      "    ann_inter = EV.times_to_intervals(ann_bounds)\n",
      "    P, R, F = mir_eval.boundary.detection(ann_inter, synth_inter, window=3, trim=False)\n",
      "    return F, P, R\n",
      "\n",
      "excerpt_ds = pd.DataFrame()\n",
      "for i, excerpt in enumerate(excerpts):\n",
      "    ds_entry = {}\n",
      "    ds_entry[\"id\"] = i\n",
      "    ds_entry[\"track_id\"] = os.path.basename(excerpt[0])\n",
      "    excerpt_bounds = get_excerpt_bounds(excerpt)\n",
      "#     print excerpt_bounds\n",
      "#     print np.diff(excerpt_bounds)\n",
      "#     print excerpt[1], excerpt[2], np.argmax(np.diff(excerpt_bounds)) + excerpt[2]\n",
      "    \n",
      "    # Get extra and less bounds\n",
      "    extra_bounds = get_extra_bounds(excerpt_bounds, N=2)\n",
      "    less_bounds = get_less_bounds(excerpt_bounds, N=2)\n",
      "    \n",
      "    ds_entry[\"v1F\"], ds_entry[\"v1P\"], ds_entry[\"v1R\"] = eval_bounds(extra_bounds, excerpt_bounds)\n",
      "    ds_entry[\"v3F\"], ds_entry[\"v3P\"], ds_entry[\"v3R\"] = eval_bounds(less_bounds, excerpt_bounds)\n",
      "    \n",
      "    excerpt_ds = excerpt_ds.append(ds_entry, ignore_index=True)\n",
      "    # Create temporary file\n",
      "    start_time = excerpt[1][excerpt[2]] - t_offset\n",
      "    end_time = excerpt[1][excerpt[2]] + th + t_offset\n",
      "    AB.mp32wav(excerpt[0], tmp_file)\n",
      "    \n",
      "    AB.add_boundaries(tmp_file, extra_bounds, \n",
      "                      output=os.path.join(out_folder, \"%d_v1.wav\" % i),\n",
      "                      start=start_time, end=end_time)\n",
      "    AB.add_boundaries(tmp_file, excerpt_bounds, \n",
      "                      output=os.path.join(out_folder, \"%d_v2.wav\" % i),\n",
      "                      start=start_time, end=end_time)\n",
      "    AB.add_boundaries(tmp_file, less_bounds, \n",
      "                      output=os.path.join(out_folder, \"%d_v3.wav\" % i),\n",
      "                      start=start_time, end=end_time)\n",
      "\n",
      "excerpt_ds.to_csv(\"excerpts.csv\", sep='\\t', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}